{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1598 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessamento do dataset de treinamento\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'dataset/training_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessamento do dataset de teste\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'dataset/test_set',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializando a CNN\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 1 - Convolution\n",
    "#input_shape só é necessário na primeira camada, ja'que é a camada ao lado da input layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 3 - Flatenning\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 5 - Output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "50/50 [==============================] - 10s 183ms/step - loss: 0.6099 - accuracy: 0.6564 - val_loss: 0.6114 - val_accuracy: 0.7075\n",
      "Epoch 2/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.4585 - accuracy: 0.7897 - val_loss: 0.4589 - val_accuracy: 0.8050\n",
      "Epoch 3/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.4339 - accuracy: 0.7966 - val_loss: 0.6511 - val_accuracy: 0.7000\n",
      "Epoch 4/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.4270 - accuracy: 0.8116 - val_loss: 0.5213 - val_accuracy: 0.7525\n",
      "Epoch 5/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.4116 - accuracy: 0.8179 - val_loss: 0.4392 - val_accuracy: 0.7900\n",
      "Epoch 6/25\n",
      "50/50 [==============================] - 8s 161ms/step - loss: 0.3992 - accuracy: 0.8323 - val_loss: 0.4171 - val_accuracy: 0.8025\n",
      "Epoch 7/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.3711 - accuracy: 0.8292 - val_loss: 0.7159 - val_accuracy: 0.6900\n",
      "Epoch 8/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.3602 - accuracy: 0.8404 - val_loss: 0.5003 - val_accuracy: 0.7800\n",
      "Epoch 9/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.3694 - accuracy: 0.8398 - val_loss: 0.4862 - val_accuracy: 0.7675\n",
      "Epoch 10/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.3694 - accuracy: 0.8454 - val_loss: 0.4990 - val_accuracy: 0.7525\n",
      "Epoch 11/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.3360 - accuracy: 0.8617 - val_loss: 0.4150 - val_accuracy: 0.8150\n",
      "Epoch 12/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.3277 - accuracy: 0.8554 - val_loss: 0.3923 - val_accuracy: 0.8100\n",
      "Epoch 13/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.3408 - accuracy: 0.8592 - val_loss: 0.4659 - val_accuracy: 0.7925\n",
      "Epoch 14/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.3021 - accuracy: 0.8698 - val_loss: 0.5857 - val_accuracy: 0.7550\n",
      "Epoch 15/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.2950 - accuracy: 0.8817 - val_loss: 0.4543 - val_accuracy: 0.8125\n",
      "Epoch 16/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.2967 - accuracy: 0.8786 - val_loss: 0.4319 - val_accuracy: 0.8050\n",
      "Epoch 17/25\n",
      "50/50 [==============================] - 8s 161ms/step - loss: 0.2879 - accuracy: 0.8874 - val_loss: 0.6471 - val_accuracy: 0.7450\n",
      "Epoch 18/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.2747 - accuracy: 0.8836 - val_loss: 0.5819 - val_accuracy: 0.7725\n",
      "Epoch 19/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.2580 - accuracy: 0.8917 - val_loss: 0.4089 - val_accuracy: 0.8150\n",
      "Epoch 20/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.2615 - accuracy: 0.8924 - val_loss: 0.4875 - val_accuracy: 0.8100\n",
      "Epoch 21/25\n",
      "50/50 [==============================] - 8s 159ms/step - loss: 0.2650 - accuracy: 0.8905 - val_loss: 0.4260 - val_accuracy: 0.8125\n",
      "Epoch 22/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.2509 - accuracy: 0.8974 - val_loss: 0.3897 - val_accuracy: 0.8275\n",
      "Epoch 23/25\n",
      "50/50 [==============================] - 8s 160ms/step - loss: 0.2319 - accuracy: 0.9093 - val_loss: 0.4872 - val_accuracy: 0.8000\n",
      "Epoch 24/25\n",
      "50/50 [==============================] - 8s 158ms/step - loss: 0.2273 - accuracy: 0.9086 - val_loss: 0.6217 - val_accuracy: 0.7725\n",
      "Epoch 25/25\n",
      "50/50 [==============================] - 8s 161ms/step - loss: 0.2048 - accuracy: 0.9149 - val_loss: 0.4899 - val_accuracy: 0.8250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ef11f1cd90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treinando a CNN\n",
    "cnn.fit(x=training_set, validation_data=test_set, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "lasagna\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.utils as image\n",
    "test_image = image.load_img('dataset/frango3.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'steak'\n",
    "else:\n",
    "    prediction = 'lasagna'\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lasagna': 0, 'steak': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
